# 实验二：「类ChatGPT通用对话系统」实验指导书（2025年） 
## 一、实验内容
类ChatGPT的通用对话系统是基于人工智能的技术，能够理解和生成自然语言，以模拟人类对话方式进行用户互动。其重要性体现在提高效率、便捷信息获取与教育、辅助决策、促进跨语言文化交流以及娱乐和创意产生等多个方面，极大地促进了信息处理的效率和多领域的发展。
在构建类ChatGPT的通用对话系统时，使用有监督微调（Supervised Fine-Tuning, SFT）对大型模型进行训练至关重要。SFT是一种深度学习技术，它涉及将已经在大型数据集上预训练的模型继续训练于一个较小、特定任务相关的、标注好的数据集上。这个过程通过调整模型的权重和参数，使其更好地适应特定任务，如图像识别或语言处理。SFT特别适用于数据较少的情况，能够显著提高模型在特定任务上的性能。SFT的主要目的是提高模型在特定任务和领域的性能和精度。通过SFT，模型可以针对特定行业或专业领域进行优化，改进对特殊语言变体或方言的理解，并减少原始训练集中可能存在的偏差和错误。此外，SFT还有助于提升用户体验，使模型的响应更符合用户的具体需求和场景，同时提高处理特定查询的效率和响应速度。
在本实验中，同学们需要实现一个类ChatGPT的中文通用对话系统，选定基座中文LLM后对其进行SFT，具体实验步骤如下：
- 基座模型选择：选择一个已经在中文上进行过预训练的大型语言模型。
  - 考虑到评测的需要，所选模型必须能够被transformers库中的AutoModelForCausalLM类加载；
  - 所用中文LLM可以从huggingface models页查找并下载，使用前务必确保所选模型为LLM且支持中文；
  - 考虑到实验环境的限制，建议选择参数量在3B以下的模型（例如，可以选择MiniCPM）。
- SFT数据：同学们需自行获取或构造中文SFT数据。可以从互联网上搜索开源的中文SFT数据集，或者自行设计和创建。
  - 首先，每位同学需要自行编写哈工大相关的SFT数据，作为一部分SFT数据；
  - 在哈工大SFT数据的基础上，为了保证模型的通用能力，需要混合更加广泛的SFT数据。可以以“中文 SFT 数据”为关键词使用google搜索相关数据（例如，可以参考该网址中的数据）。
- SFT：使用上一步中获取的微调数据，对选用的中文LLM进行SFT。
  - 建议使用Alpaca相关代码来进行模型微调，同学们也可自行编写代码。
  - 为确保微调和评测时prompt的一致性，微调时应使用以下固定格式的prompt：
<|beginofutterance|>系统
（Instruction）
<|endofutterance|>
<|beginofutterance|>用户
（Question）
<|endofutterance|>
<|beginofutterance|>智能助手
（Answer）
<|endofutterance|>
## 二、提交内容
由于模型较大，同学们的实验提交内容请上传到此提交连接：

提交文件的名称为“学号-姓名.zip”，包含以下内容：
1. 经过SFT微调的LLM，应能被transformers.AutoModelForCausalLM加载；
2. 实验代码，其中应包含模型的微调日志；
3. 微调所用的SFT数据；
4. 实验报告（实验报告模板.docx）
## 三、评分标准
助教会使用同学们提交的微调好的LLM，对给定的问题生成答案。之后，会使用ChatGPT 3.5对同学们的模型生成的答案进行打分，综合打分结果和同学实验报告，作为实验成绩。具体分数组成如下：
1. 自行标注若干条哈工大SFT数据（5分）；
2. 提交的模型可运行，并且能生成较流畅的中文回复（5分）；
3. 助教评测各位同学提交的模型在SFT评测数据上的运行结果（5分）；
4. 提交完整具体的实验报告（5分）。

<br><br><br>

需要了解Hugging Face库相关函数，网上搜索SFT相关关键词可了解相关信息
