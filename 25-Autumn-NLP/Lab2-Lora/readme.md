# 一、实验内容
Transformer模型是一种通用的深度学习架构，已经在各种自然语言处理和其他领域的任务中取得了巨大成功。其中Decoder-only的Transformer模型（如GPT系列）在许多领域中发挥着重要作用。这种模型主要集中于生成任务。
在本实验中，请你基于实验提供的代码框架，实现一个Decoder-only的Transformer模型——GPT，并使用SkyPile中文预训练数据集的一个子集进行模型训练。 

非常简单，代码框架已给出，只需填空即可。
（直接丢给gpt就行）
